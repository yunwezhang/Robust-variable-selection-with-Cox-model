This folder contains saved .RData files. Due to the limited space, other saved files can be obtained by emailing the corresponding author. 

For all methods, run details are as the following:  
For each simulation scenario, we ran 100 repeats and performed the evaluation within each repeat. We use the “set.seed” function in R to ensure reproducibility of our results. For various outlier percentages, 0.1% as an example, a “ceiling” function in R is used so that we ended up with 1 outlying observation. For methods 1 to 8, they were implemented using the “hdnom”  R package. We applied the 10 fold cross validation for each run to select the optimal tuning parameter for the corresponding penalty. Then we refitted the model using the selected optimal parameter. For method 9 to 11, the “pawph” github functions were used. “Alpha” is set to be 0.5, “seed“ is set to be equal to 1 and all other tuning parameters were set to the default value. For “pawph_mcp”, the auxiliary variable value is 3 and for “pawph_scad” it is 3.7 as suggested in the “glmnet” package. For method 12, we applied the “SIS” function in the “SIS” package with “family=”cox”, penalty=”lasso”, tune=”bic”, varISIS=”cons”, seed=41, nfolds=10, type.measure=”deviance” as the suggested use for Cox SIS. For method 13, the “crq” function in the “quantreg” package is used with method=”Portnoy” to obtain weights for variables, then through the “penalty.factor” argument in the “cv.glmnet” function, the inverse of these weights were fed into the Lasso Cox model. For method 14 and 15, robust weights were applied through the “weights” argument in the “cv.glmnet” function. 
