---
title: "Robust cox model attempt 8 real data"
author: "Yunwei Zhang"
date: “`r paste0('Initiated on 20240609, compiled on ', format(Sys.time(), '%Y %b %d'))`”
output:
  
  html_document:
    code_folding: hide
    fig_height: 8
    fig_width: 12
    highlight: tango
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: yes
      smooth_scroll: no
  pdf_document:
    toc: yes
    toc_depth: '4'
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE,message = FALSE)
#usethis::edit_r_environ()
#R_MAX_VSIZE=700Gb
```

This file is used to wrap up findings for paper. for real data amalysis on the uvm cancer data.

```{r}
.libPaths("/dskh/nobackup/yunwei/robust_methods_codes/library")
setwd("/dskh/nobackup/yunwei/robust_methods_codes")
library(inline)
openblas.set.num.threads <- cfunction( signature(ipt="integer"),
                                       body = "openblas_set_num_threads(*ipt);",
                                       otherdefs = c ("extern void openblas_set_num_threads(int);"),
                                       libargs = c ("/usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3"),
                                       language = "C",
                                       convention = ".C"
)
openblas.set.num.threads(1)
#install.packages("Matrix",version="1.6.4")
# #package_version("Matrix")
library(Matrix)
#install.packages("htmltools",version="0.5.7")
#library(htmltools)
library(dplyr)
library(MXM)
library(survival)
library(limma)
library(glmnet)
library(ncvreg)
library(ggplot2)
library(caret)
library(Hmisc)
library(SIS)
source('prcox.R')
library(MASS)
#install.packages('ncvreg2_3.13.0.tar.gz', repos=NULL, type='source')
library(ncvreg2)
library(gbm)
library(coxrobust)
library(rbsurv)
library(faux)
library(pbmcapply)
library(ggpubr)
library(hdnom)
library(quantreg)
library(purrr)
library(reshape2)
library(data.table)
```



# functions to be used for evaluation

report: all estimated values in a data frame, mean of estimated values, sum absolute diff, sum squred diff, median model size, true positive (true variables selected >50%), false positive (false variables selected >50%), estimated probability that the true model is selected
```{r}
summary_table_fun=function(run_result,design_params){
my_list=sapply(run_result,function(x) x[[1]],simplify = FALSE)

# Extract all unique names
all_names <- unique(unlist(lapply(my_list, "[",1)))

# Create a matrix with 0s
matrix_data <- matrix(0, nrow = length(my_list), ncol = length(all_names), dimnames = list(names(my_list), all_names))

# Fill in the matrix with values from the named vectors
for (i in seq_along(my_list)) {
  temp_dt=as.data.frame(my_list[[i]])
  names_i <- temp_dt$Name
  matrix_data[i, names_i] <- temp_dt$Value
}

# Function to fill NA with 0 and convert to numeric
fill_na_convert_numeric <- function(x) {
  x[is.na(x)] <- 0
  as.numeric(x)
}

# Apply the function to each column of the matrix
matrix_data <- apply(matrix_data, 2, fill_na_convert_numeric)

# Convert the matrix to a data frame
result_df <- as.data.frame(matrix_data)

# delete zeros for final results
final_df=round(colMeans(result_df,na.rm = TRUE),2)
final_df=final_df[final_df!=0]

# get abs diff
# #vectors_to_subtract=data.frame(X1=1,X2=1,X3=1,X4=1,X5=1,X6=1,X30=1)
# vectors_to_subtract=design_params
# columns_to_subtract <- names(vectors_to_subtract)
# col_name=colnames(result_df)
# data=as.data.frame(matrix(0,nrow=nrow(result_df),ncol=length(columns_to_subtract)))
# colnames(data)=columns_to_subtract
# # Subtract vectors from corresponding columns
# for (i in 1:length(columns_to_subtract)) {
#    col_index <- which(colnames(result_df) == col_name[i])
#   data[, col_index] <- abs(result_df[, col_index] - vectors_to_subtract[[col_name[i]]])
# }
# final_df2=colSums(data,na.rm = TRUE)
final_df2=data.frame(matrix(nrow=nrow(design_params),ncol = ncol(design_params)))
vectors_to_subtract=design_params
for(i in 1:length(colnames(design_params))){
  if(length(final_df)==0){final_df2=NA}else if(length(which(names(final_df) == colnames(design_params)[i]))==0){
    final_df2[1,i]=abs(design_params[i])
  }else{
final_df2[1,i]=abs(final_df[which(names(final_df) == colnames(design_params)[i])]-design_params[i])}
  }
#colnames(final_df2)=colnames(design_params)
# get squared error
# #vectors_to_subtract=data.frame(X1=1,X2=1,X3=1,X4=1,X5=1,X6=1,X30=1)
# vectors_to_subtract=design_params
# columns_to_subtract <- names(vectors_to_subtract)
# col_name=colnames(result_df)
# data=as.data.frame(matrix(0,nrow=nrow(result_df),ncol=length(columns_to_subtract)))
# colnames(data)=columns_to_subtract
# # Subtract vectors from corresponding columns
# for (i in 1:length(columns_to_subtract)) {
#    col_index <- which(colnames(result_df) == col_name[i])
#   data[, col_index] <- (result_df[, col_index] - vectors_to_subtract[[col_name[i]]])^2
# }
# final_df3=colSums(data,na.rm = TRUE)
final_df3=data.frame(matrix(nrow=nrow(design_params),ncol = ncol(design_params)))
vectors_to_subtract=design_params
for(i in 1:length(colnames(design_params))){
  if(length(final_df)==0){final_df3=NA}else if(length(which(names(final_df) == colnames(design_params)[i]))==0){
    final_df3[1,i]=abs(design_params[i])^2
  }else{
final_df3[1,i]=(final_df[which(names(final_df) == colnames(design_params)[i])]-design_params[i])^2}
  }
#colnames(final_df3)=colnames(design_params)
return(list(result_df,final_df,final_df2,final_df3))
}

summary_table_fun2=function(run_result,design_params){
my_list=sapply(run_result,function(x) x[[1]],simplify = FALSE)

# Extract all unique names
all_names <- unique(unlist(lapply(my_list, names)))

# Create a matrix with 0s
matrix_data <- matrix(0, nrow = length(my_list), ncol = length(all_names), dimnames = list(names(my_list), all_names))

# Fill in the matrix with values from the named vectors
for (i in seq_along(my_list)) {
  names_i <- names(my_list[[i]])
  matrix_data[i, names_i] <- my_list[[i]]
}

# Function to fill NA with 0 and convert to numeric
fill_na_convert_numeric <- function(x) {
  x[is.na(x)] <- 0
  as.numeric(x)
}

# Apply the function to each column of the matrix
matrix_data <- apply(matrix_data, 2, fill_na_convert_numeric)

# Convert the matrix to a data frame
result_df <- as.data.frame(matrix_data)

# delete zeros for final results
final_df=round(colMeans(result_df,na.rm = TRUE),2)
final_df=final_df[final_df!=0]
# get abs diff
# #vectors_to_subtract=data.frame(X1=1,X2=1,X3=1,X4=1,X5=1,X6=1,X30=1)
# vectors_to_subtract=design_params
# columns_to_subtract <- names(vectors_to_subtract)
# col_name=colnames(result_df)
# data=as.data.frame(matrix(0,nrow=nrow(result_df),ncol=length(columns_to_subtract)))
# colnames(data)=columns_to_subtract
# # Subtract vectors from corresponding columns
# for (i in 1:length(columns_to_subtract)) {
#    col_index <- which(colnames(result_df) == col_name[i])
#   data[, col_index] <- abs(result_df[, col_index] - vectors_to_subtract[[col_name[i]]])
# }
# final_df2=colSums(data,na.rm = TRUE)
final_df2=data.frame(matrix(nrow=nrow(design_params),ncol = ncol(design_params)))
vectors_to_subtract=design_params
for(i in 1:length(colnames(design_params))){
  if(length(final_df)==0){final_df2=NA}else if(length(which(names(final_df) == colnames(design_params)[i]))==0){
    final_df2[1,i]=abs(design_params[i])
  }else{
final_df2[1,i]=abs(final_df[which(names(final_df) == colnames(design_params)[i])]-design_params[i])}
}
#colnames(final_df2)=colnames(design_params)
# get squared error
# #vectors_to_subtract=data.frame(X1=1,X2=1,X3=1,X4=1,X5=1,X6=1,X30=1)
# vectors_to_subtract=design_params
# columns_to_subtract <- names(vectors_to_subtract)
# col_name=colnames(result_df)
# data=as.data.frame(matrix(0,nrow=nrow(result_df),ncol=length(columns_to_subtract)))
# colnames(data)=columns_to_subtract
# # Subtract vectors from corresponding columns
# for (i in 1:length(columns_to_subtract)) {
#    col_index <- which(colnames(result_df) == col_name[i])
#   data[, col_index] <- (result_df[, col_index] - vectors_to_subtract[[col_name[i]]])^2
# }
# final_df3=colSums(data,na.rm = TRUE)
final_df3=data.frame(matrix(nrow=nrow(design_params),ncol = ncol(design_params)))
vectors_to_subtract=design_params
for(i in 1:length(colnames(design_params))){
  if(length(final_df)==0){final_df3=NA}else if(length(which(names(final_df) == colnames(design_params)[i]))==0){
    final_df3[1,i]=abs(design_params[i])^2
  }else{
final_df3[1,i]=(final_df[which(names(final_df) == colnames(design_params)[i])]-design_params[i])^2}
  }
#colnames(final_df3)=colnames(design_params)

return(list(result_df,final_df,final_df2,final_df3))
}

#calculation
calculation_fun=possibly(function(result,given_names){
list_of_dataframes<-list()
for (i in 1:100){
  list_of_dataframes[[i]]=result[[i]][[1]]
}

# Extract the first column ('characteristics') from each dataframe and skip if an error occurs
character_columns <- lapply(list_of_dataframes, function(df) {
  tryCatch({
    return(df$Name)
  }, error = function(e) {
    return(NULL)
  })
})

# Remove NULL elements
character_columns <- character_columns[!sapply(character_columns, is.null)]

# get model size
model_size=sapply(character_columns,length)

#get true mdoel proportion
true_num=0
for(i in 1:length(character_columns)){
  vec1=sort(character_columns[[i]])
  vec2=sort(given_names)
  equal=all(vec1==vec2)
  if(equal==TRUE){
    true_num=true_num+1
  }else{true_num=true_num}
}
# Combine character columns into a single vector
all_characters <- unlist(character_columns)

# Count occurrences of each character
character_counts <- table(all_characters)

#update 0315:all counts >half are determied as selected
character_counts_vector <- names(character_counts[character_counts>50])
# Function to calculate TP, FP, and F1 score
calculate_tp_fp_f1 <- function(true_names, predicted_names) {
  # Calculate TP and FP
  tp <- sum(predicted_names %in% true_names)
  fp <- sum(!(predicted_names %in% true_names))

  # Calculate F1 score
  precision <- tp / (tp + fp)
  recall <- tp / length(true_names)

  # Handle cases where precision + recall is 0
  if (precision + recall == 0) {
    return(list(tp = tp, fp = fp, f1_score = 0))
  }

  f1_score <- 2 * (precision * recall) / (precision + recall)

  return(list(tp = tp, fp = fp, f1_score = f1_score))
}

#given_names=colnames(dd)
# Calculate TP, FP, and F1 score based on given names and character counts
result <- calculate_tp_fp_f1(given_names, character_counts_vector)

return(list(result,character_counts,model_size,true_num))}, otherwise=list(list(0,0,0),0,0,0))




calculation_fun2=possibly(function(result,given_names){
list_of_dataframes<-list()
for (i in 1:100){
  list_of_dataframes[[i]]=result[[i]][[1]]
}

# Extract the first column ('characteristics') from each dataframe and skip if an error occurs
character_columns <- lapply(list_of_dataframes, function(df) {
  tryCatch({
    return(names(df))
  }, error = function(e) {
    return(NULL)
  })
})

# Remove NULL elements
character_columns <- character_columns[!sapply(character_columns, is.null)]

# get model size
model_size=sapply(character_columns,length)

#get true mdoel proportion
true_num=0
for(i in 1:length(character_columns)){
  vec1=sort(character_columns[[i]])
  vec2=sort(given_names)
  equal=all(vec1==vec2)
  if(equal==TRUE){
    true_num=true_num+1
  }else{true_num=true_num}
}

# Combine character columns into a single vector
all_characters <- unlist(character_columns)

# Count occurrences of each character
character_counts <- table(all_characters)

#update 0315:all counts >half are determied as selected
character_counts_vector <- names(character_counts[character_counts>50])
# Function to calculate TP, FP, and F1 score
calculate_tp_fp_f1 <- function(true_names, predicted_names) {
  # Calculate TP and FP
  tp <- sum(predicted_names %in% true_names)
  fp <- sum(!(predicted_names %in% true_names))

  # Calculate F1 score
  precision <- tp / (tp + fp)
  recall <- tp / length(true_names)

  # Handle cases where precision + recall is 0
  if (precision + recall == 0) {
    return(list(tp = tp, fp = fp, f1_score = 0))
  }

  f1_score <- 2 * (precision * recall) / (precision + recall)

  return(list(tp = tp, fp = fp, f1_score = f1_score))
}

#given_names=colnames(dd)
# Calculate TP, FP, and F1 score based on given names and character counts
result <- calculate_tp_fp_f1(given_names, character_counts_vector)

return(list(result,character_counts,model_size,true_num))}, otherwise=list(list(0,0,0),0,0,0))

```

# functions for fitting the model
```{r}
result_cal=function(current_data2,model_name){
  X=as.matrix(current_data2[,!colnames(current_data2)%in%c("time","status")])
  y=Surv(current_data2$time,current_data2$status)
  time=current_data2$time
  status=current_data2$status
  if(model_name=="pawph"){
    model6 <- prcoxreg(y,X, seed=1, alpha= 0.5)
    # PAWPH estimator
    result=model6$betaHat_re
    output=result[result!=0]}
  if(model_name=="ncvreg"){
    #ncvreg
    method1<-ncvreg::cv.ncvsurv(X,y,gamma=3,penalty="MCP",alpha=1,nfolds=10)
    result=method1$fit$beta[,which(method1$fit$lambda==method1$lambda.min)]
    output=result[result!=0]
  }
  if(model_name=="SIS"){
    model2=SIS(X,y,family='cox', penalty='lasso', tune='bic', varISIS='cons',seed=41,nfolds = 10,type.measure = "deviance")
    #colnames(X)[model2$ix]
    result=model2$coef.est
    output=result[result!=0]
  }
  if(model_name=="SIS_mcp"){
    model2=SIS(X,y,family='cox', penalty='MCP', tune='bic', varISIS='cons',seed=41,nfolds = 10,type.measure = "deviance")
    #colnames(X)[model2$ix]
    result=model2$coef.est
    output=result[result!=0]
  }
  if(model_name=="SIS_scad"){
    model2=SIS(X,y,family='cox', penalty='SCAD', tune='bic', varISIS='cons',seed=41,nfolds = 10,type.measure = "deviance")
    #colnames(X)[model2$ix]
    result=model2$coef.est
    output=result[result!=0]
  }
  if(model_name=="MXM"){
    model3<-SES(y,X,max_k=3,threshold=0.01,test="censIndCR")
    output=rep(1,length(colnames(X)[model3@selectedVars]))
    names(output)=colnames(X)[model3@selectedVars]
  }
  if(model_name=="coxrobust"){
    PredictorVariables <- colnames(X)
    Formula <- formula(paste("Surv(time,status) ~ ", paste(PredictorVariables, collapse=" + ")))
    model4=coxr(Formula,data=current_data2)#the leading minor of order 2 is not positive, this cannot process this dummy variable one...
    result=model4$coefficients#robust est
    output=result[result!=0]
  }
  if(model_name=="rbsurv"){
    model5<-rbsurv(time=time,status=status,x=as.matrix(t(current_data2[,!colnames(current_data2)%in%c("time","status")])), method="efron",n.iter=10,n.fold=10, n.seq=1) #need a row column transformation
    output=rep(1,length(model5$gene.list))
    names(output)=colnames(X)[as.numeric(model5$gene.list)]
  }
  if(model_name=="lasso"){
    #lasso
    fitlasso1<-hdnom::fit_lasso(X, Surv(time, status), nfolds = 10, rule = "lambda.min")
    mat=fitlasso1$model$beta
    non_zero_indices <- which(mat[] != 0, arr.ind = TRUE)
    non_zero_values_lasso1 <- data.frame(
      Name = rownames(mat)[non_zero_indices[, 1]],
      Value = mat@x
    )
    output=non_zero_values_lasso1
  }
  if(model_name=="enet"){
    #enet
    fitenet1<-hdnom::fit_enet(X, Surv(time, status), nfolds = 10, rule = "lambda.min")
    mat=fitenet1$model$beta
    non_zero_indices <- which(mat[] != 0, arr.ind = TRUE)
    non_zero_values_enet1 <- data.frame(
      Name = rownames(mat)[non_zero_indices[, 1]],
      Value = mat@x
    )
    output=non_zero_values_enet1
  }
  if(model_name=="alasso"){
    #alasso
    fitlasso1<-hdnom::fit_alasso(X, Surv(time, status), nfolds = 10, rule = "lambda.min")
    mat=fitlasso1$model$beta
    non_zero_indices <- which(mat[] != 0, arr.ind = TRUE)
    non_zero_values_lasso1 <- data.frame(
      Name = rownames(mat)[non_zero_indices[, 1]],
      Value = mat@x
    )
    output=non_zero_values_lasso1
  }
  if(model_name=="aenet"){
    #aenet
    fitenet1<-hdnom::fit_aenet(X, Surv(time, status), nfolds = 10, rule = "lambda.min")
    mat=fitenet1$model$beta
    non_zero_indices <- which(mat[] != 0, arr.ind = TRUE)
    non_zero_values_enet1 <- data.frame(
      Name = rownames(mat)[non_zero_indices[, 1]],
      Value = mat@x
    )
    output=non_zero_values_enet1
  }
  if(model_name=="scad"){
    #alasso
    fitlasso1<-hdnom::fit_scad(X, Surv(time, status), nfolds = 10)
    mat=fitlasso1$model$beta
    non_zero_indices <- which(mat[] != 0, arr.ind = TRUE)
    non_zero_values_lasso1 <- data.frame(
      Name = rownames(mat)[non_zero_indices[, 1]],
      Value = mat[non_zero_indices[, 1],1]
    )
    output=non_zero_values_lasso1
  }
  if(model_name=="mnet"){
    #aenet
    fitenet1<-hdnom::fit_mnet(X, Surv(time, status), nfolds = 10)
    mat=fitenet1$model$beta
    non_zero_indices <- which(mat[] != 0, arr.ind = TRUE)
    non_zero_values_lasso1 <- data.frame(
      Name = rownames(mat)[non_zero_indices[, 1]],
      Value = mat[non_zero_indices[, 1],1]
    )
    output=non_zero_values_lasso1
  }
  if(model_name=="snet"){
    #aenet
    fitenet1<-hdnom::fit_snet(X, Surv(time, status), nfolds = 10)
    mat=fitenet1$model$beta
    non_zero_indices <- which(mat[] != 0, arr.ind = TRUE)
    non_zero_values_lasso1 <- data.frame(
      Name = rownames(mat)[non_zero_indices[, 1]],
      Value = mat[non_zero_indices[, 1],1]
    )
    output=non_zero_values_lasso1
  }
  if(model_name=="mcp"){
    #aenet
    fitenet1<-hdnom::fit_mcp(X, Surv(time, status), nfolds = 10)
    mat=fitenet1$model$beta
    non_zero_indices <- which(mat[] != 0, arr.ind = TRUE)
    non_zero_values_lasso1 <- data.frame(
      Name = rownames(mat)[non_zero_indices[, 1]],
      Value = mat[non_zero_indices[, 1],1]
    )
    output=non_zero_values_lasso1
  }
  if(model_name=="weighted_enet"){
    #my attempt
    weight_vec=ifelse(time<=median(time)&status==0,0.5,ifelse(time>median(time)&status==0,1,2))
    fit=cv.glmnet(X,y, family = "cox",nfolds = 10,alpha=0.5,weights=weight_vec)
    want=coef(fit, s = 'lambda.min')[coef(fit, s = 'lambda.min')[,1]!= 0]
    names=rownames(coef(fit, s = 'lambda.min'))[coef(fit, s = 'lambda.min')[,1]!= 0]
    # output=cbind.data.frame(names,want)
    # colnames(output)=c("Names","Value")
    output=want
    names(output)=names
  }
  if(model_name=="weighted_lasso"){
    #my attempt
    weight_vec=ifelse(time<=median(time)&status==0,0.5,ifelse(time>median(time)&status==0,1,2))
    fit=cv.glmnet(X,y, family = "cox",nfolds = 10,alpha=1,weights=weight_vec)
    want=coef(fit, s = 'lambda.min')[coef(fit, s = 'lambda.min')[,1]!= 0]
    names=rownames(coef(fit, s = 'lambda.min'))[coef(fit, s = 'lambda.min')[,1]!= 0]
    # output=cbind.data.frame(names,want)
    # colnames(output)=c("Names","Value")
    output=want
    names(output)=names
  }
  if(model_name=="my"){
    #my attempt
    f<-crq(y~X,method="Portnoy") 
    #coefficients(f)[-1,1]
    # add in the weights
    fit=cv.glmnet(X,y, family = "cox",penalty.factor = 1/abs(as.numeric(rowMeans(coefficients(f)[-1,2:3]))),alpha=1)
    want=coef(fit, s = 'lambda.min')[coef(fit, s = 'lambda.min')[,1]!= 0]
    names=rownames(coef(fit, s = 'lambda.min'))[coef(fit, s = 'lambda.min')[,1]!= 0]
    output=cbind.data.frame(names,want)
    colnames(output)=c("Names","Value")
  }
  if(model_name=="my2"){
    fitlasso1<-hdnom::fit_lasso(X, Surv(time, status), nfolds = 10, rule = "lambda.min")
    mat=fitlasso1$model$beta
    non_zero_indices <- which(mat[] != 0, arr.ind = TRUE)
    non_zero_values_lasso1 <- data.frame(
      Name = rownames(mat)[non_zero_indices[, 1]],
      Value = mat@x
    )
    names=non_zero_values_lasso1$Name
    X2=X[,colnames(X)%in%names]
    #my attempt
    f<-quantreg::crq(y~X2,method="Portnoy") 
    want=as.numeric(coef(f)[-1,1])
    output=cbind.data.frame(names,want)
    colnames(output)=c("Names","Value")
  }
  return(list(output,table(current_data2$status)))
}
```



# uvm data
```{r}
current_data=read.csv("UVM.csv")
current_data2=current_data
colnames(current_data2)[(dim(current_data2)[2]-2):dim(current_data2)[2]]=c("control_var","status","time")
current_data2$time=as.numeric(current_data2$time)
current_data2=current_data2[current_data2$time>0,]
current_data2=current_data2[!is.na(current_data2$time),]
dim(current_data)
dim(current_data2)
table(current_data2$control_var)
current_data2$control_var=ifelse(current_data2$control_var=="FEMALE",0,1) #female is group0 as the proportion control
# set.seed(230720)
# rownum=sample(nrow(current_data2),nrow(current_data2)*0.2,replace = FALSE)
# ex_validation=current_data2[rownum,]
# current_data2=current_data2[-rownum,]
# dim(ex_validation)
# dim(current_data2)
table(current_data2$status)
summary(current_data2$time)
hist(current_data2$time)
# #define the data with control_var to run the with control_var method
# current_data3=current_data2
# external_validation3=ex_validation
# dim(current_data3)
# dim(external_validation3)
# #get datasets do not include gender to run other methods
current_data2=current_data2[,-which(colnames(current_data2)=="control_var")]
# ex_validation=ex_validation[,-which(colnames(ex_validation)=="control_var")]
# dim(ex_validation)
current_data2=current_data2[,-1]
dim(current_data2)

# #calculation of correlation matrix
# numeric_data=current_data2[,-which(colnames(current_data2)%in%c("time","status"))]
# # library(Rfast)
# # cov_matrix=cova(as.matrix(numeric_data),center = FALSE,large=TRUE)
# # saveRDS(cov_matrix,"uvm_cov_matrix.rds")
# cov_matrix=readRDS("uvm_cov_matrix.rds")
# mu.x=as.numeric(apply(as.matrix(numeric_data),2,mean))

# #fit a mode to get betas
# tr_matrix=data.matrix(numeric_data)
#   tr_st=current_data2$time
#   tr_y=current_data2$status
# fit <- fit_lasso(tr_matrix, Surv(tr_st, tr_y), nfolds = 5, rule = "lambda.min")
# #fit$model$beta[!fit$model$beta==0]
# mat=fit$model$beta
# non_zero_indices <- which(mat[] != 0, arr.ind = TRUE)
# non_zero_values <- data.frame(
#   Name = rownames(mat)[non_zero_indices[, 1]],
#   Value = mat@x
# )
# saveRDS(non_zero_values,"uvm_non_zero_values.rds")
# non_zero_values=readRDS("uvm_non_zero_values.rds")
# non_zero_values2=non_zero_values
# non_zero_values2$Value=round(non_zero_values2$Value,1)
# non_zero_values2=non_zero_values2[which(non_zero_values2$Value!=0),]


# #find the estimated baseline hazard and exp params
# #approach 1
# est.model=coxph(as.formula(paste("Surv(time,status)~", paste(non_zero_values$Name, collapse="+"))),data=current_data2)
#       haz <- basehaz(est.model)
#       # any(is.na(haz))
#       # any(is.infinite(haz$hazard))
#       # any(is.infinite(haz$time))
#       # any(is.nan(haz$hazard))
#       # any(is.nan(haz$time))
#       # class(haz$hazard)
#       # class(haz$time)
#       haz=as.data.frame(haz)
#       dim(haz)
#       haz.new=haz[haz$hazard>0&haz$time>0,]
#       bhaz.model <- lm(log(hazard)~log(time),data=haz.new)
#       shape.init <- bhaz.model$coef[2]
#       scale.init <- exp(bhaz.model$coef[1]/bhaz.model$coef[2])
#       k.shape<-shape.init
#       h0=scale.init
#       
# #approach 2  
#  # calculate neg logl of PH model with Weibull basehazard
# nlogl.parSurv <- function(p,data,x,z,status) {
# # p = parameters of the survival model
# # exp(p[1]) = scale par of base hazard
# # exp(p[2]) = shape par of base hazard
# # exp(p[3..]) = HR, last value = gamma
# # data = data frame containing data we want to fit, contains the following vars
# #    t1.MI   = start of interval
# #    t2.MI   = end of interval
# #    status    = 1 if onset observed, 0 if censored
# # x  = matrix of fixed covariates
# # z  = vector of time dependent covariates
# scale    <- exp(p[1])
# shape    <- exp(p[2])
# X        <- cbind(x,z)
# npar     <- ncol(X)
# betagamma<- as.matrix(p[3:(2+npar)])
# cum.hzrd <- ( (scale*data$t2.MI)^shape - (scale*data$t1.MI)^shape)*exp(as.matrix(X)%*%as.matrix(betagamma))
# hazard   <- shape*(scale^shape)*data$t2.MI^(shape-1)*exp(as.matrix(X)%*%as.matrix(betagamma))
# # calculate log-likelihood
# logl <- -cum.hzrd + log(hazard)*(status==1)
# # return -logl
# -sum(logl)
# }
# 
# #formatting example data3 to use our own function
# example_data3=current_data2
# example_data3$t1.MI=rep(0,dim(example_data3)[1])
# example_data3$t2.MI=example_data3$time
# 
# real_estimate=optim(par=c(h0,k.shape,non_zero_values$Value),fn=nlogl.parSurv,data=example_data3,x=example_data3[,non_zero_values$Name],z=rep(0,dim(example_data3)[1]),status=example_data3$status)$par
# real_estimate=optim(par=c(1,1,non_zero_values$Value),fn=nlogl.parSurv,data=example_data3,x=example_data3[,non_zero_values$Name],z=rep(0,dim(example_data3)[1]),status=example_data3$status)$par
# real_estimate
# #function cannot be evaluated at initial parameters
```


```{r}
lasso_result=result_cal(current_data2,model_name="lasso")
enet_result=result_cal(current_data2,model_name="enet")
alasso_result=result_cal(current_data2,model_name="alasso")
aenet_result=result_cal(current_data2,model_name="aenet")
mcp_result=result_cal(current_data2,model_name="mcp")
scad_result=result_cal(current_data2,model_name="scad")
mnet_result=result_cal(current_data2,model_name="mnet")
snet_result=result_cal(current_data2,model_name="snet")

source("prcox.R")
pawph_result=result_cal(current_data2,model_name="pawph")
source("prcox_my.R")
pawphmcp_result=result_cal(current_data2,model_name="pawph")
source("prcox_my2.R")
pawphscad_result=result_cal(current_data2,model_name="pawph")

sis_result=result_cal(current_data2,model_name="SIS")

alasso_result=NA
mcp_result=NA
scad_result=NA
pawph_result=NA
save(lasso_result,enet_result,alasso_result,aenet_result,mcp_result,scad_result,mnet_result,snet_result,pawph_result,pawphmcp_result,pawphscad_result,sis_result,file="uvm_real_result0612.RData")


sis_result1=sis_result[[1]]
ids=gsub("X", "", names(sis_result1))
ids2=as.numeric(ids)+21
names(sis_result1)=colnames(current_data2)[ids2]

lasso_result1=lasso_result[[1]]$Value
names(lasso_result1)=lasso_result[[1]]$Name
enet_result1=enet_result[[1]]$Value
names(enet_result1)=enet_result[[1]]$Name
mnet_result1=mnet_result[[1]]$Value
names(mnet_result1)=mnet_result[[1]]$Name
snet_result1=snet_result[[1]]$Value
names(snet_result1)=snet_result[[1]]$Name

sis_result1=sis_result[[1]]
ids=gsub("X", "", names(sis_result1))
ids2=as.numeric(ids)+21
names(sis_result1)=colnames(current_data2)[ids2]

my_list=list(lasso_result1,enet_result1,mnet_result1,snet_result1,pawphmcp_result[[1]],pawphscad_result[[1]],sis_result1)

# Extract all unique names
all_names <- unique(unlist(lapply(my_list, names)))

# Create an empty data frame with these names
df <- data.frame(matrix(ncol = length(all_names), nrow = length(my_list)))
colnames(df) <- all_names

# Fill the data frame with values
for (i in seq_along(my_list)) {
  df[i, names(my_list[[i]])] <- my_list[[i]]
}

# df$method=factor(c("lasso","enet","mnet","snet","pawph_mcp","pawph_scad","sis"),levels = c("lasso","enet","mnet","snet","pawph_mcp","pawph_scad","sis"))
df$method=factor(c("lasso","enet","mnet","snet","pawph_mcp","pawph_scad","sis"),levels = c("sis","mnet","snet","enet","lasso","pawph_mcp","pawph_scad"))

df=df[,!colnames(df)%in%c("BMP10.27302")]

gg_heatmap_data <- melt(df, id.vars = c("method"), variable.name = "variables")
gg_heatmap_data$value=round(gg_heatmap_data$value,1)

gg_heatmap_data <- gg_heatmap_data %>%
  mutate(across(everything(), ~ replace(., . == 0, NA)))

variables_with_all_na <- gg_heatmap_data %>%
  group_by(variables) %>%
  summarize(all_na = all(is.na(value))) %>%
  filter(all_na) %>%
  pull(variables)

# Remove rows with these variables
data_long <- gg_heatmap_data %>%
  filter(!variables %in% variables_with_all_na)



ggheatmap <-ggplot(data_long, aes(variables, method, fill= value)) +
 geom_tile(color = "grey")+scale_fill_gradientn(limits = c(-4,4),colours = c("#2166AC", "#67A9CF" ,"#D1E5F0", "#FFFFFF","#FDDBC7", "#EF8A62", "#B2182B"))+ theme(aspect.ratio = 1, text = element_text(size = 15), legend.position = "bottom") + labs(y= 'Method', x = "Variables", fill = 'Estimated params')+theme_bw()+theme(axis.text.x = element_text(color = "black", size = 15,angle = 90),axis.text.y = element_text(color = "black", size = 16))+
  geom_text(aes(label = round(value,1)), color = "black", size = 4)
ggheatmap
ggsave(ggheatmap,filename="uvm_heatmap0612.pdf",width = 17,height = 8)
ggsave(ggheatmap,filename="uvm_heatmap0613.pdf",width = 17,height = 8)
# all_cal_list=list(calculation_fun(lasso_result),calculation_fun(result2),calculation_fun2(pawph_result),calculation_fun2(result4),calculation_fun2(result5))
#
# final_cal_table=as.data.frame(matrix(0,nrow=5,ncol=3))
# for(i in 1:5){
#   for(j in 1:3){
#     final_cal_table[i,j]=all_cal_list[[i]][[1]][[j]]
#   }
# }
# final_cal_table

data_wide <- data_long %>%
  pivot_wider(names_from = variables, values_from = value)

colnames(df)
corr_matrix=cor(current_data2[,colnames(current_data2)%in%data_long$variables])
desired_order <- intersect(colnames(df), colnames(corr_matrix))

# Reorder the correlation matrix
ordered_corr_matrix <- corr_matrix[desired_order, desired_order]

library(corrplot)
# Plot the correlation matrix
#corrplot(corr_matrix, method = "color", type = "upper", tl.col = "black", tl.srt = 45, addCoef.col = "black")
corrplot(ordered_corr_matrix, method = "color", type = "upper", 
         addCoef.col = NULL, tl.cex = 0.8, cl.cex = 0.8, col = colorRampPalette(c("navyblue","blue","green", "white","orange", "red","darkred"))(200),tl.col = "black")
corrplot(ordered_corr_matrix, method = "color", type = "upper", 
         addCoef.col = NULL, tl.cex = 0.8, cl.cex = 0.8, col = colorRampPalette(c("blue", "white", "red"))(200),tl.col = "black")
```



